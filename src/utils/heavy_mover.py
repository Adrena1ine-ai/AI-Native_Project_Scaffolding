"""
Heavy Mover â€” Move heavy files to external storage and generate bridges.
The core of the "Deep Clean & Bridge" system.
"""

from __future__ import annotations

import json
import os
import shutil
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from .token_scanner import FileCategory, HeavyFile, ScanResult

try:
    from ..core.constants import VERSION
except ImportError:
    VERSION = "3.4.0"


@dataclass
class MovedFile:
    """Record of a moved file."""
    original_path: Path          # Original location in project
    original_relative: str       # Relative to project root
    external_path: Path          # New location in external storage
    external_relative: str       # Relative to external root
    size_bytes: int
    estimated_tokens: int
    category: FileCategory
    schema: Optional[Dict] = None
    moved_at: str = field(default_factory=lambda: datetime.now().isoformat())


@dataclass
class MoveResult:
    """Result of moving heavy files."""
    project_path: Path
    project_name: str
    external_dir: Path
    moved_files: List[MovedFile] = field(default_factory=list)
    failed_files: List[Tuple[str, str]] = field(default_factory=list)  # (path, error)
    config_paths_file: Optional[Path] = None
    manifest_file: Optional[Path] = None
    
    @property
    def total_moved_tokens(self) -> int:
        return sum(mf.estimated_tokens for mf in self.moved_files)
    
    @property
    def success_count(self) -> int:
        return len(self.moved_files)
    
    @property
    def failed_count(self) -> int:
        return len(self.failed_files)


def get_external_dir(project_path: Path) -> Path:
    """
    Get external storage directory for project.
    
    Structure:
        ../_data/PROJECT_NAME/LARGE_TOKENS/
    
    Creates directory if not exists.
    """
    project_path = project_path.resolve()
    project_name = project_path.name
    external = project_path.parent / "_data" / project_name / "LARGE_TOKENS"
    external.mkdir(parents=True, exist_ok=True)
    return external


def move_heavy_files(
    project_path: Path,
    heavy_files: List[HeavyFile],
    dry_run: bool = False
) -> MoveResult:
    """
    Move heavy files to external storage.
    
    Args:
        project_path: Path to project root
        heavy_files: List of HeavyFile from token_scanner
        dry_run: If True, only simulate (don't actually move)
    
    Returns:
        MoveResult with list of moved files and any errors
    
    Process:
        1. Create external directory structure
        2. Move each file, preserving relative structure
        3. Generate manifest.json
        4. Generate config_paths.py
    """
    project_path = project_path.resolve()
    external_dir = get_external_dir(project_path)
    
    result = MoveResult(
        project_path=project_path,
        project_name=project_path.name,
        external_dir=external_dir
    )
    
    for hf in heavy_files:
        try:
            # Calculate destination path (preserve structure)
            dest_path = external_dir / hf.relative_path
            
            if not dry_run:
                # Create parent directories
                dest_path.parent.mkdir(parents=True, exist_ok=True)
                
                # Move file
                shutil.move(str(hf.path), str(dest_path))
            
            # Record move
            moved = MovedFile(
                original_path=hf.path,
                original_relative=hf.relative_path,
                external_path=dest_path,
                external_relative=str(dest_path.relative_to(external_dir)),
                size_bytes=hf.size_bytes,
                estimated_tokens=hf.estimated_tokens,
                category=hf.category,
                schema=hf.schema
            )
            result.moved_files.append(moved)
            
        except Exception as e:
            result.failed_files.append((hf.relative_path, str(e)))
    
    if not dry_run and result.moved_files:
        # Generate config_paths.py
        result.config_paths_file = generate_config_paths(
            project_path, result.moved_files, external_dir
        )
        
        # Generate manifest.json
        result.manifest_file = generate_manifest(
            project_path, result.moved_files, external_dir
        )
    
    return result


def generate_config_paths(
    project_path: Path,
    moved_files: List[MovedFile],
    external_dir: Path
) -> Path:
    """
    Generate config_paths.py with bridges to external files.
    
    Output file structure:
    ```python
    # Auto-generated by AI Toolkit Deep Clean
    # DO NOT EDIT â€” regenerate with `toolkit doctor --deep-clean`
    
    from pathlib import Path
    
    # External storage location
    EXTERNAL_DATA = Path(__file__).parent.parent / "_data" / "PROJECT" / "LARGE_TOKENS"
    
    # File mappings (original name â†’ external path)
    FILES_MAP = {
        "data/products.json": EXTERNAL_DATA / "data/products.json",
        "logs/app.log": EXTERNAL_DATA / "logs/app.log",
    }
    
    # Helper function
    def get_path(original: str) -> Path:
        '''Get external path for original file location.'''
        if original in FILES_MAP:
            return FILES_MAP[original]
        raise FileNotFoundError(f"No external mapping for: {original}")
    
    # Schemas (structure without data)
    SCHEMAS = {
        "data/products.json": {
            "type": "json",
            "schema": {"type": "object", "keys": {...}}
        },
    }
    ```
    """
    project_name = project_path.name
    
    # Build file mappings
    mappings = []
    schemas = []
    
    for mf in moved_files:
        # Use forward slashes for consistency
        orig_key = mf.original_relative.replace("\\", "/")
        # Escape backslashes in path strings
        escaped_path = orig_key.replace("\\", "\\\\")
        mappings.append(f'    "{orig_key}": EXTERNAL_DATA / "{escaped_path}",')
        
        if mf.schema:
            # Convert JSON to Python-compatible format
            schema_str = json.dumps(mf.schema, indent=8, ensure_ascii=False)
            # Replace JSON booleans with Python booleans
            schema_str = schema_str.replace("true", "True").replace("false", "False").replace("null", "None")
            schemas.append(f'    "{orig_key}": {schema_str},')
    
    # Generate Python code
    code = f'''"""
Auto-generated by AI Toolkit Deep Clean
DO NOT EDIT â€” regenerate with `toolkit doctor --deep-clean`

Generated: {datetime.now().isoformat()}
Project: {project_name}
Files moved: {len(moved_files)}
"""
from pathlib import Path

# External storage location
# Relative to project root: ../_data/{project_name}/LARGE_TOKENS/
EXTERNAL_DATA = Path(__file__).parent.parent / "_data" / "{project_name}" / "LARGE_TOKENS"

# File mappings (original relative path â†’ external Path)
FILES_MAP = {{
{chr(10).join(mappings)}
}}


def get_path(original: str) -> Path:
    """
    Get external path for original file location.
    
    Usage:
        from config_paths import get_path
        data = json.load(open(get_path("data/products.json")))
    
    Args:
        original: Original relative path (e.g., "data/products.json")
    
    Returns:
        Path to file in external storage
    
    Raises:
        FileNotFoundError: If no mapping exists
    """
    # Normalize path separators
    normalized = original.replace("\\\\", "/")
    
    if normalized in FILES_MAP:
        return FILES_MAP[normalized]
    
    raise FileNotFoundError(
        f"No external mapping for: {{original}}\\n"
        f"Available files: {{list(FILES_MAP.keys())}}"
    )


def exists(original: str) -> bool:
    """Check if file exists in external storage."""
    try:
        return get_path(original).exists()
    except FileNotFoundError:
        return False


def list_files() -> list:
    """List all files in external storage."""
    return list(FILES_MAP.keys())


# Schemas (structure without data, for AI context)
SCHEMAS = {{
{chr(10).join(schemas) if schemas else "    # No schemas extracted"}
}}


def get_schema(original: str) -> dict:
    """Get schema for a file (structure without data)."""
    normalized = original.replace("\\\\", "/")
    return SCHEMAS.get(normalized, {{}})
'''
    
    # Write file
    config_path = project_path / "config_paths.py"
    config_path.write_text(code, encoding="utf-8")
    
    return config_path


def generate_manifest(
    project_path: Path,
    moved_files: List[MovedFile],
    external_dir: Path
) -> Path:
    """
    Generate manifest.json in external directory.
    
    Contains full record of what was moved for recovery.
    
    Structure:
    {
        "project": "my_bot",
        "created": "2024-12-24T12:00:00",
        "toolkit_version": "3.4",
        "files": [
            {
                "original": "data/products.json",
                "external": "data/products.json",
                "tokens": 50000,
                "category": "data",
                "schema": {...}
            }
        ]
    }
    """
    manifest = {
        "project": project_path.name,
        "project_path": str(project_path),
        "external_dir": str(external_dir),
        "created": datetime.now().isoformat(),
        "toolkit_version": VERSION,
        "total_files": len(moved_files),
        "total_tokens": sum(mf.estimated_tokens for mf in moved_files),
        "files": [
            {
                "original": mf.original_relative,
                "external": mf.external_relative,
                "size_bytes": mf.size_bytes,
                "tokens": mf.estimated_tokens,
                "category": mf.category.value,
                "schema": mf.schema,
                "moved_at": mf.moved_at
            }
            for mf in moved_files
        ]
    }
    
    manifest_path = external_dir / "manifest.json"
    manifest_path.write_text(
        json.dumps(manifest, indent=2, ensure_ascii=False),
        encoding="utf-8"
    )
    
    return manifest_path


def restore_files(
    project_path: Path,
    manifest_path: Optional[Path] = None
) -> int:
    """
    Restore moved files back to original locations.
    
    Args:
        project_path: Path to project root
        manifest_path: Path to manifest.json (auto-detect if None)
    
    Returns:
        Number of files restored
    """
    project_path = project_path.resolve()
    
    # Find manifest
    if manifest_path is None:
        manifest_path = (
            project_path.parent / "_data" / project_path.name / 
            "LARGE_TOKENS" / "manifest.json"
        )
    
    if not manifest_path.exists():
        raise FileNotFoundError(f"Manifest not found: {manifest_path}")
    
    # Load manifest
    manifest = json.loads(manifest_path.read_text(encoding="utf-8"))
    external_dir = Path(manifest["external_dir"])
    
    restored = 0
    for file_info in manifest["files"]:
        external_path = external_dir / file_info["external"]
        original_path = project_path / file_info["original"]
        
        if external_path.exists():
            # Create parent directories
            original_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Move back
            shutil.move(str(external_path), str(original_path))
            restored += 1
    
    # Remove config_paths.py
    config_paths = project_path / "config_paths.py"
    if config_paths.exists():
        config_paths.unlink()
    
    return restored


def format_move_report(result: MoveResult) -> str:
    """
    Format move result as readable report.
    
    Example:
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  ğŸ“¦ DEEP CLEAN â€” Files Moved to External Storage                 â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  Project: my_bot                                                 â•‘
    â•‘  External: ../_data/my_bot/LARGE_TOKENS/                         â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  âœ… MOVED (12 files, 4.8M tokens):                               â•‘
    â•‘  â”œâ”€ data/products.json        â†’  LARGE_TOKENS/data/products.json â•‘
    â•‘  â”œâ”€ data/users.csv            â†’  LARGE_TOKENS/data/users.csv     â•‘
    â•‘  â””â”€ logs/app.log              â†’  LARGE_TOKENS/logs/app.log       â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ğŸ“„ Generated:                                                   â•‘
    â•‘  â”œâ”€ config_paths.py (bridge to external files)                   â•‘
    â•‘  â””â”€ manifest.json (recovery info)                                â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ğŸ’¡ Update imports: from config_paths import FILES_MAP, get_path â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    lines = []
    
    lines.append("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    lines.append("â•‘  ğŸ“¦ DEEP CLEAN â€” Files Moved to External Storage                 â•‘")
    lines.append("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    
    lines.append(f"â•‘  Project: {result.project_name:<55}â•‘")
    
    # Show external path relative to project
    ext_rel = f"../_data/{result.project_name}/LARGE_TOKENS/"
    lines.append(f"â•‘  External: {ext_rel:<54}â•‘")
    
    if result.moved_files:
        total_tokens = result.total_moved_tokens
        tokens_str = f"{total_tokens/1_000_000:.1f}M" if total_tokens >= 1_000_000 else f"{total_tokens/1_000:.0f}K"
        
        lines.append("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        lines.append(f"â•‘  âœ… MOVED ({len(result.moved_files)} files, {tokens_str} tokens):{' '*(35-len(tokens_str))}â•‘")
        
        for i, mf in enumerate(result.moved_files[:10]):
            prefix = "â””â”€" if i == min(len(result.moved_files), 10) - 1 else "â”œâ”€"
            orig = mf.original_relative[:25]
            if len(mf.original_relative) > 25:
                orig = orig[:22] + "..."
            dest = f"LARGE_TOKENS/{mf.external_relative}"[:30]
            if len(f"LARGE_TOKENS/{mf.external_relative}") > 30:
                dest = dest[:27] + "..."
            line = f"â•‘  {prefix} {orig:<25} â†’ {dest:<30}"
            padding = 67 - len(line) + 1
            lines.append(line + " " * padding + "â•‘")
        
        if len(result.moved_files) > 10:
            lines.append(f"â•‘  ... and {len(result.moved_files) - 10} more files{' '*45}â•‘")
    
    if result.failed_files:
        lines.append("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        lines.append(f"â•‘  âŒ FAILED ({len(result.failed_files)} files):{' '*44}â•‘")
        for path, error in result.failed_files[:5]:
            path_short = path[:30]
            error_short = error[:25]
            lines.append(f"â•‘  â”œâ”€ {path_short:<30}: {error_short:<25}{' '*5}â•‘")
    
    lines.append("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    lines.append("â•‘  ğŸ“„ Generated:                                                   â•‘")
    if result.config_paths_file:
        lines.append("â•‘  â”œâ”€ config_paths.py (bridge to external files)                   â•‘")
    if result.manifest_file:
        lines.append("â•‘  â””â”€ manifest.json (recovery info)                                â•‘")
    
    lines.append("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    lines.append("â•‘  ğŸ’¡ Update imports: from config_paths import get_path            â•‘")
    lines.append("â•‘  ğŸ’¡ Restore files:  toolkit doctor --restore                     â•‘")
    lines.append("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    return "\n".join(lines)

